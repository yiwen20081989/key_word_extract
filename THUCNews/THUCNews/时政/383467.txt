科学家研制骗子机器人可能将学会欺骗人类
　　英国《每日邮报》9月13日(北京时间)的一篇文章，以“现实版《2001太空漫游》”作为大标题，报道了一台能够欺骗其他机器人、甚至欺骗人类的智能机器人。据研制机器人的科学家称，这应是世界上第一例涉及机器人“欺骗行为”而进行的实验。论文刊登在《国际社交机器人技术杂志》上。
　　在美国电影大师斯坦利·库布里克的殿堂级作品《2001太空漫游》中，宇宙飞船上一台名叫“哈尔”的智能电脑，劫持了飞船并施计杀死了4名机组人员，表现出人工智能的精湛“骗术”。
　　一直以来，人们认为这只是科幻电影中的场景，但现在，美国佐治亚州理工学院的科学家罗纳德·亚金率领的研究小组编写出了一套计算机运算法则，该高科技程序能让机器人自主决定它是否面临危险，以及是否应该通过欺骗另一个机器人或一个人的方式，让自己安全地躲藏起来，而不被敌人发现。
　　为了防止机器人滥用“骗术”，科学家使其必须先满足两个必要条件后，才能获得行使欺骗行为的授权：其一，它和搜寻者之间必须有冲突；其二，它可以从欺骗行为中获得益处。再然后，科学家利用相互依存理论和博弈论开发出算法，测试欺骗行为可以获得的收益，以教会机器人在辨别眼前的形势后决定是否需要行使欺骗行为，并让它能根据对“敌方”的了解程度，而调整欺骗策略以赢取最佳效果。
　　在实验中，科学家让两个机器人进行了20次“躲猫猫”游戏。其中安装了新程序的“机器小骗子”多次制造出假的运动轨迹，顺利躲过了另一个机器人的搜寻；但该机器人也会因为没能成功施展出计划中的骗术，被后者逮到而失败，然而，整个实验中，骗术成功的概率达75%。研究合作者、工程师艾伦·瓦格纳称：“它虽不甚完美，但仍证明新技术及算法可使机器人于杂乱环境下施行骗术。”
　　尽管有些人期待着“机器小骗子”在军事上“大展拳脚”，但包括研究者本身在内的多数人，都看到了这其中暗含的伦理问题。他们担心，假如某一天人工智能摆脱了人类意志而自行设下迷魂阵，届时现实版的《2001太空漫游》就将“粉墨登场”。
　　研究人员一致认为，必须保证机器人这些行为和预期完全一致并对社会有益。他们建议，就“骗子”机器人的适合性展开讨论，争取制订出束缚这一系统的规章制度和指导方针。(记者 张梦然)
　　总编辑圈点 
　　与其说机器人学会了骗人类，不如说是人类在骗自己玩儿，这样的事随时都会在我们身边发生，不算稀奇。这位机器人兄弟是很了不起，但其本身并不能自主思考，举手投足间所反映的还是主人的高明。而就人工智能水平而言，亚金这一作品也未超越当年因战胜国际象棋大师卡斯帕罗夫而名噪一时的IBM超级计算机“深蓝”。凭藉预置若干出色的程序，机器人的行为让人喜出望外，仅此而已。这时候就谈论相关的伦理问题，未免有哗众取宠之嫌。

