谷歌图书团队称全世界约有1.3亿本图书
　　导语：谷歌公司谷歌图书(Google Books)团队在其官方博客上发表博文称，其统计了截至2010年8月1号全世界所有图书的数量，一共约1亿2986万4880本。科技博客CrunchGear发表评论文章对谷歌图书计划做了评论，认为该计划实施难度巨大，但影响将会不可估量。以下是评论全文：
　　谷歌的目标一直是将地球上所有的数据都电子化、分类、索引到其巨大的服务器里。谷歌图书恐怕是这个巨大的工程中最有野心的布局之一。但是不要忘了，人类将文字和智慧记载入图书里已经有了五、六千年的历史，书的数量可以说不计其数。谷歌图书将使世界上所有的图书都可以在线搜索，影响将是不可估量的。谷歌为了完成这一浩大的工程，使用了当今很多最新的科技手段。
　　谷歌图书团队刚刚在其官方博客发了一篇博客，讲述了他们是如何计算出世界上所有的图书有1亿2986万4880本这个他们认为相对准确的数字的。
　　其实我对他们具体是如何得出这一数字并不感兴趣，但是我很乐意看到他们主动去挑战海量的数据。因为这意味着，在未来我们还有很多东西可以学习，还有很多关于如何处理数据的问题会被提出。
　　举个例子说：谷歌要处理非常多类似于ISBN(国际标准书号)的图书数据，还要与众多大学图书馆、公共图书馆、私人收藏、博物馆等等非常多的机构合作，处理这些机构提供的相似的图书记录，并区分出这些记录的微小差异。设计高效的算法来从这些重叠非常多的图书记录中找到每一本书的最初版本不是一件容易的事，毫无疑问需要频繁的人工干预。谷歌需要使用了类似于算法的程序区分、分类、分析大量的图片。
　　使用OCR(光学字符识别)技术扫描图书并非易事。例如：错误率要控制在多少？对于不同印刷技术的书是否需要不同的扫描仪？是否需要人工整理书页的褶皱？手动翻书的人的手指盖住了部分内容怎么办？如此之类的问题数不胜举。
　　当然，书籍作品本身的规律一定程度上降低了扫描工作的难度。大部分图书作品都有很清晰的开头和结尾，期刊和杂志都是按期发行编号清晰等等。
　　另一个问题是，如何存档存有巨量信息的因特网？现在有人在做这种工作，可是问题是他们如何将每一个网站都以一个标准的模式整体打包？一个名为 Internet Archive的网站就在做整个因特网的存档工作。但是我怀疑这项工作真的那么有意义吗？因为我们现在根本就看不懂两千年前的数据，那两千年以后的人能看懂现在保存的数据吗？
　　让一个商业化的公司把人类所有的信息都电子化是一件耸人听闻的事。当然，我不反对谷歌这么做，而且我认为这是谷歌所做的为数不多的合法、免费贡献给全世界的好产品之一。毫无疑问，谷歌会在这些电子书中卖广告，但是它为了将这一工程商业化所花费的财力人力巨大，它有权利这么做。毕竟在过去，自由获得取信息还只是少数人的特权，而谷歌图书将会彻底改变这一点。(张和)

